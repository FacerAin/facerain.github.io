---
isTIL: false
date: "2022-01-23"
title: "[5분 NLP] 언어 모델 평가 지표 PPL 알아보기"
categories: ["NLP"]
summary: "언어 모델을 평가할 때 사용되는 PPL 지표에 대해서 알아봅시다."
thumbnail: "./nlp-ppl/th.jpg"
---
이번 시간에는 **언어 모델을 평가할 때 사용하는** 지표인 **PPL(Perplexity)** 에 대해서 알아봅니다.

## PPL의 의미
A와 B 두가지 언어 모델이 있다고 가정해봅시다. 두가지 중 어떤 언어 모델의 성능이 더 좋다고 말할 수 있을까요?  
모델 간 성능 비교를 위해서는 **평가 지표**라는 것이 필요합니다. **언어 모델(Language Model)을 평가할 때 사용하는 지표 중 하나가 바로 PPL 입니다.**
**PPL은 테스트 문장을 이용하여 빠르고 간단하게 모델을 평가할 수 있다는 것이 특징입니다.**

PPL(Perplexity)는 perplexed라는 영어 단어에서 의미를 따왔습니다. perplexed는 한국어로 **헷갈리는** 이라는 의미를 가지고 있습니다.
PPL이란 언어 모델이 문장을 생성할 때 *헷갈리는* 정도를 의미합니다.  
PPL이 낮다는 것은 그만큼 언어 모델이 문장을 생성할 때 덜 헷갈린다는 뜻입니다. **즉, PPL이 낮을수록 대체로 성능이 좋은 언어모델을 뜻합니다.**  
하지만 여기서 주의할 점은 PPL이 낮다고 무조건 좋은 언어 모델은 아니라는 것입니다. PPL이 낮은 모델에서 생성한 문장이라도 사람 입장에서는 어색한 문장일수 있습니다. 따라서 PPL을 측정할 때는 많은 양의 그리고 도메인에 알맞는 테스트 문장들을 이용했는지 확인해야합니다.  



 

## PPL 어떻게 구할까요?
PPL은 아래와 같은 수식으로 구할 수 있습니다.
$$
PPL(W)=P(w_{1}, w_{2}, w_{3}, ... , w_{N})^{-\frac{1}{N}}=\sqrt[N]{\frac{1}{P(w_{1}, w_{2}, w_{3}, ... , w_{N})}}
$$

위 식에서 $P(w_{1}, w_{2}, w_{3}, ... , w_{N})$ 은 언어 모델에서 주어진 문장이 나타날 확률을 의미합니다. 확률값들의 기하 평균을 구하고, 역수를 취한 것이 바로 PPL입니다. 이때 N은 문장의 길이를 의미합니다.
만약 언어 모델이 주어진 문장을 생성할 확률이 높다면 PPL이 낮아지게 됩니다. 여기서 PPL을 측정할 때는 미리 준비한 테스트 문장들을 사용합니다.     

> Q. 확률값들의 기하평균을 취해주는 이유는 무엇인가요?  
> A. 문장을 생성할 확률인 $P(w_{1}, w_{2}, w_{3}, ... , w_{N})$ 은 문장이 길어질수록 매우 작은 확률값을 가지게 됩니다. 왜냐하면 조건부확률의 연쇄법칙에 의해 1보다 작은 확률값들을 계속 곱해주기 때문입니다. 이를 방지하기 위해 곱의 평균을 의미하는 기하 평균을 취해주게 되는 것입니다.  

위 식을 **n-gram** 에 대해서도 적용할 수 있습니다.  
**연쇄 법칙** 을 이용하면 아래와 같이 나타낼 수 있습니다.
$$
PPL(W)=\sqrt[N]{\frac{1}{P(w_{1}, w_{2}, w_{3}, ... , w_{N})}}=\sqrt[N]{\frac{1}{\prod_{i=1}^{N}P(w_{i}| w_{1}, w_{2}, ... , w_{i-1})}}
$$
여기에 n-gram을 적용하면 아래와 같습니다.
$$
PPL(W)=\sqrt[N]{\frac{1}{\prod_{i=1}^{N}P(w_{i}| w_{i-N+1}, ..., w_{i-1})}}
$$


## PPL과 분기(Branch)
**PPL은 모델이 단어를 선택할 때 가지는 분기(branch)의 개수를 의미하기도 합니다.**

한가지 예제를 들어보겠습니다. 1부터 6가지의 숫자가 쓰인 주사위가 있습니다. 이 주사위를 N번 던졌을 때 얻는 수열에 대한 PPL은 아래와 같이 6이 나오게 됩니다.
$$
PPL(x) = (\frac{1}{6}^N)^{-\frac{1}{N}} = 6
$$
이는 매 time-step마다 6가지의 분기가 있음이라고 해석할 수 있습니다.

마찬가지로 어떤 언어 모델의 PPL이 10이라면 해당 언어 모델은 다음 단어를 선택할 때 평균 10개의 단어 후보 중에서 선택한다고 볼 수 있습니다.
**즉, PPL이 높을수록 단어 선택의 후보군이 많다는 의미로, 모델이 단어 선택을 헷갈리고 있다는 뜻입니다.**

## PPL과 엔트로피
PPL을 엔트로피 개념에 접목시키면 아래와 같은 수식을 얻을 수 있습니다.
$$
PPL = exp(CrossEntropy)
$$
**CrossEntropy의 확률값에 지수 함수를 취해주면 간단하게 PPL을 구할 수 있습니다.** 이러한 성질덕분에 모델 학습시 PPL을 유용하게 사용할 수 있습니다.  

자세한 유도 과정은 [링크](https://kh-kim.gitbook.io/natural-language-processing-with-pytorch/00-cover-8/03-perpexity#ppl-1)를 참고해주시기 바랍니다.

## Reference
- [https://kh-kim.gitbook.io/natural-language-processing-with-pytorch/00-cover-8/03-perpexity](https://kh-kim.gitbook.io/natural-language-processing-with-pytorch/00-cover-8/03-perpexity)
- [https://wikidocs.net/21697](https://wikidocs.net/21697)