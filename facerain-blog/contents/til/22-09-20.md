---
isTIL: true
date: "2022-09-20"
title: "AITECH 2일차"
categories: ["Review", "NLP"]
summary: "AITECH 2일차 학습 내용을 회고합니다."
thumbnail: "./22-09-20-th.jpg"
---


## TL;DR
- Numpy & Pandas
- Vector & Matrix
- 경사하강법
- 함께 자라기 읽기 - 실수는 예방하는 것이 아닌 관리하는 것
## 내적
- 정사영된 벡터의 길이와 관련이 있음.
- 내적은 정사영의 길이를 벡터  y의 길이 |y|만큼 조정한 값임.
- 내적은 두 벡터의 유사도를 측정하는데 유용하다.

## 행렬 곱셈
- i번째 행벡터와 j번째 열벡터 사이의 내적을 성분으로 가지는 행렬을 계산.

## 행렬의 의미
- 벡터가 공간에서 한 점을 의미한다면 행렬은 여러 점들은 나타낸다.
- 어떤 데이터의 모음이라고 이해할 수 있음
- 행렬을 벡터공간에서 사용되는 연산자로도 이해할 수 있음.
- 행렬곱을 통해 벡터를 다른 차원의 공간으로 보낼 수 있음.
- 행렬곱을 통해 패턴을 추출하고 데이터를 압축할 수 있음.
- 모든 선형변환은 행렬곱으로 계산할 수 있음.

## 경사하강법
- 경사하강법은 이론적으로 미분가능하고 볼록(convex)한 함수에 대해서 수렴이 보장됨.
- 하지만 비선형회귀는 목적식이 convex하지 않을 수도 있다.
- 확률적 경사하강법 (Stochastic Gradient Descent)는 모든 데이터를 사용해서 업데이트하는 대신 데이터를 한개 또는 일부 활용하여 업데이트
- 목적식이 배치마다 다르므로, 극소점을 탈출할 가능성이 높아진다. => 머신러닝 학습에 효율적.

## 실수는 예방하는 것이 아닌 관리하는 것 (함께 자라기)
- 실수 문화에는 예방과 실수 관리 두가지가 있다.
- 하지만 실수 예방은 거의 불가능에 가깝다.
-  따라서 "실수는 어떻게든 할 수밖에 없다. 대신 그 실수가 나쁜 결과로 되기 전에 일찍 발견하고 빨리 고치면 된다" => 실수 관리
- 이미 결과가 난 실수에 대해서는 학습을 통해 다음 계획을 세우자.
- 교육 중에 실수를 더 유도해야 오히려 학습 전이가 더 잘 일어난다


## 오늘의 한 문장
실수는 어떻게든 할 수밖에 없다. 대신 그 실수가 나쁜 결과로 되기 전에 일찍 발견하고 빨리 고치면 된다